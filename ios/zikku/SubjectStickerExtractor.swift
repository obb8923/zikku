import Foundation
import UIKit
import React
import Vision
import CoreImage

@objc(SubjectStickerExtractor)
class SubjectStickerExtractor: NSObject {

  @objc
  static func requiresMainQueueSetup() -> Bool {
    // ë°±ê·¸ë¼ìš´ë“œ íì—ì„œ ì´ˆê¸°í™” ê°€ëŠ¥
    return false
  }

  // iOS ì´ë¯¸ì§€ ë¶„ì„(Subject Lifting) ì§€ì› ì—¬ë¶€ í™•ì¸
  @objc
  func isSubjectExtractionSupported(
    _ resolve: RCTPromiseResolveBlock,
    rejecter reject: RCTPromiseRejectBlock
  ) {
    if #available(iOS 17.0, *) {
      resolve(true)
    } else {
      resolve(false)
    }
  }

  // ì£¼ì…ëœ ë¡œì»¬ ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ í”¼ì‚¬ì²´ ìŠ¤í‹°ì»¤ ì¶”ì¶œ
  @objc
  func analyzeImage(
    _ path: NSString,
    resolver resolve: @escaping RCTPromiseResolveBlock,
    rejecter reject: @escaping RCTPromiseRejectBlock
  ) {
    let pathString = path as String
    
    print("ğŸ“± iOS Version: \(UIDevice.current.systemVersion)")

    guard let image = loadImage(from: pathString) else {
      reject(
        "INVALID_IMAGE",
        "Could not load image from path: \(pathString)",
        nil
      )
      return
    }
    
    print("ğŸ–¼ï¸  Image loaded: \(image.size)")

    // iOS 17 ì´ìƒë§Œ ì§€ì›
    if #available(iOS 17.0, *) {
      print("ğŸ” Using Vision Mask: iOS 17+ path")
      analyzeWithVisionMask(
        imagePath: pathString,
        resolver: resolve,
        rejecter: reject
      )
    } else {
      reject(
        "UNSUPPORTED_VERSION",
        "Subject extraction requires iOS 17.0 or later",
        nil
      )
    }
  }

  // MARK: - Vision (iOS 17+) ì „ê²½ ë§ˆìŠ¤í¬ ê²½ë¡œ

  @available(iOS 17.0, *)
  private func analyzeWithVisionMask(
    imagePath: String,
    resolver resolve: @escaping RCTPromiseResolveBlock,
    rejecter reject: @escaping RCTPromiseRejectBlock
  ) {
    // ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ CIImage ë¡œë“œ (ë°©í–¥ ì²˜ë¦¬ í¬í•¨)
    guard let ciImage = loadInputImage(from: imagePath) else {
      reject(
        "INVALID_IMAGE",
        "Failed to create CIImage from image path.",
        nil
      )
      return
    }

    let request = VNGenerateForegroundInstanceMaskRequest()
    let handler = VNImageRequestHandler(ciImage: ciImage)

    // ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬
    DispatchQueue(label: "EffectsProcessing").async {
      do {
        try handler.perform([request])
      } catch {
        DispatchQueue.main.async {
          reject(
            "ANALYSIS_FAILED",
            "Vision request failed: \(error.localizedDescription)",
            error
          )
        }
        return
      }

      guard let result = request.results?.first else {
        DispatchQueue.main.async {
          reject(
            "ANALYSIS_FAILED",
            "No subject observations found in the image.",
            nil
          )
        }
        return
      }

      do {
        // generateMaskedImageë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ë¦¬ëœ í”¼ì‚¬ì²´ ì´ë¯¸ì§€ ìƒì„±
        // generateMaskedImageëŠ” CVPixelBufferë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ CIImageë¡œ ë³€í™˜ í•„ìš”
        let maskedPixelBuffer = try result.generateMaskedImage(
          ofInstances: result.allInstances,
          from: handler,
          croppedToInstancesExtent: true
        )

        // CVPixelBufferë¥¼ CIImageë¡œ ë³€í™˜
        let maskedImage = CIImage(cvPixelBuffer: maskedPixelBuffer)
        
        // TODO: ì™¸ê³½ì„  ê¸°ëŠ¥ì€ ì¶”í›„ êµ¬í˜„
        // ì¼ë‹¨ ì›ë³¸ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©
        let imageWithOutline = maskedImage

        let context = CIContext()

        guard let cgImage = context.createCGImage(
          imageWithOutline,
          from: imageWithOutline.extent
        ) else {
          DispatchQueue.main.async {
            reject(
              "ANALYSIS_FAILED",
              "Failed to create CGImage from masked image.",
              nil
            )
          }
          return
        }

        // ì›ë³¸ ì´ë¯¸ì§€ì˜ scale ë° orientation ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ UIImage ë¡œë“œ
        guard let originalImage = self.loadImage(from: imagePath) else {
          DispatchQueue.main.async {
            reject(
              "ANALYSIS_FAILED",
              "Failed to load original image for scale information.",
              nil
            )
          }
          return
        }

        // ì›ë³¸ ì´ë¯¸ì§€ì˜ ë°©í–¥ ì •ë³´ë¥¼ ìœ ì§€
        let resultImage = UIImage(
          cgImage: cgImage,
          scale: originalImage.scale,
          orientation: originalImage.imageOrientation
        )

        guard let data = resultImage.pngData() else {
          DispatchQueue.main.async {
            reject(
              "ANALYSIS_FAILED",
              "Failed to convert result image to PNG data.",
              nil
            )
          }
          return
        }

        let fileName = "subject_sticker_mask_\(UUID().uuidString).png"
        let tempDir = NSTemporaryDirectory()
        let url = URL(fileURLWithPath: tempDir).appendingPathComponent(fileName)

        do {
          try data.write(to: url, options: .atomic)

          let osVersion = UIDevice.current.systemVersion
          let method = "visionMask"

          let item: [String: Any] = [
            "id": "0",
            "uri": url.absoluteString,
            "width": resultImage.size.width,
            "height": resultImage.size.height,
            "osVersion": osVersion,
            "method": method
          ]

          DispatchQueue.main.async {
            resolve([item])
          }
        } catch {
          DispatchQueue.main.async {
            reject(
              "ANALYSIS_FAILED",
              "Failed to save sticker image: \(error.localizedDescription)",
              error
            )
          }
        }
      } catch {
        DispatchQueue.main.async {
          reject(
            "ANALYSIS_FAILED",
            "Failed to generate masked image: \(error.localizedDescription)",
            error
          )
        }
      }
    }
  }

  // MARK: - Helpers

  private func loadImage(from path: String) -> UIImage? {
    if path.hasPrefix("file://") {
      if let url = URL(string: path) {
        return UIImage(contentsOfFile: url.path)
      }
    }

    return UIImage(contentsOfFile: path)
  }

  private func loadInputImage(from path: String) -> CIImage? {
    guard let uiImage = loadImage(from: path) else {
      return nil
    }
    
    guard var ciImage = CIImage(image: uiImage) else {
      return nil
    }
    
    // EXIF ë°©í–¥ ì •ë³´ í™•ì¸ ë° ì ìš©
    if let orientation = ciImage.properties["Orientation"] as? Int32, orientation != 1 {
      ciImage = ciImage.oriented(forExifOrientation: orientation)
    }
    
    return ciImage
  }
  
  // MARK: - ì™¸ê³½ì„  ì¶”ê°€
  
  /// ì´ë¯¸ì§€ì— í°ìƒ‰ ì™¸ê³½ì„ ì„ ì¶”ê°€í•©ë‹ˆë‹¤
  private func addWhiteOutline(to image: CIImage, mask: CIImage) -> CIImage {
    // ì™¸ê³½ì„  ë‘ê»˜ (í”½ì…€ ë‹¨ìœ„)
    let outlineWidth: CGFloat = 2.0
    
    // 1. ë§ˆìŠ¤í¬ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (ì•ŒíŒŒ ì±„ë„ë¡œ ì‚¬ìš©)
    let grayMask = mask.applyingFilter("CIColorMatrix", parameters: [
      "inputRVector": CIVector(x: 0, y: 0, z: 0, w: 0.2126),
      "inputGVector": CIVector(x: 0, y: 0, z: 0, w: 0.7152),
      "inputBVector": CIVector(x: 0, y: 0, z: 0, w: 0.0722),
      "inputAVector": CIVector(x: 0, y: 0, z: 0, w: 1),
      "inputBiasVector": CIVector(x: 0, y: 0, z: 0, w: 0)
    ])
    
    // 2. Morphology í•„í„°ë¡œ ë§ˆìŠ¤í¬ í™•ì¥ (ê²½ê³„ ê°ì§€)
    guard let morphFilter = CIFilter(name: "CIMorphologyMaximum") else {
      return image
    }
    morphFilter.setValue(grayMask, forKey: kCIInputImageKey)
    morphFilter.setValue(outlineWidth, forKey: kCIInputRadiusKey)
    
    guard let expandedMask = morphFilter.outputImage else {
      return image
    }
    
    // 3. í™•ì¥ëœ ë§ˆìŠ¤í¬ì—ì„œ ì›ë³¸ ë§ˆìŠ¤í¬ë¥¼ ë¹¼ì„œ ê²½ê³„ë§Œ ì¶”ì¶œ
    guard let subtractFilter = CIFilter(name: "CIDifferenceBlendMode") else {
      return image
    }
    subtractFilter.setValue(expandedMask, forKey: kCIInputImageKey)
    subtractFilter.setValue(grayMask, forKey: kCIInputBackgroundImageKey)
    
    guard let outlineMask = subtractFilter.outputImage else {
      return image
    }
    
    // 4. ê²½ê³„ë¥¼ í°ìƒ‰ìœ¼ë¡œ ì¹ í•˜ê¸°
    let whiteOutline = outlineMask.applyingFilter("CIColorMatrix", parameters: [
      "inputRVector": CIVector(x: 0, y: 0, z: 0, w: 1),
      "inputGVector": CIVector(x: 0, y: 0, z: 0, w: 1),
      "inputBVector": CIVector(x: 0, y: 0, z: 0, w: 1),
      "inputAVector": CIVector(x: 0, y: 0, z: 0, w: 1),
      "inputBiasVector": CIVector(x: 0, y: 0, z: 0, w: 0)
    ])
    
    // 5. ì›ë³¸ ì´ë¯¸ì§€ì™€ í°ìƒ‰ ì™¸ê³½ì„  í•©ì„±
    guard let compositeFilter = CIFilter(name: "CISourceOverCompositing") else {
      return image
    }
    compositeFilter.setValue(whiteOutline, forKey: kCIInputImageKey)
    compositeFilter.setValue(image, forKey: kCIInputBackgroundImageKey)
    
    return compositeFilter.outputImage ?? image
  }
}


